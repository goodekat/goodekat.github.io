<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>presentations.knit</title>

<script src="site_libs/header-attrs-2.16/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img id="logo" style="width: 80px;" src="/images/star.png" /></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="papers.html">Papers</a>
</li>
<li>
  <a href="presentations.html">Presentations</a>
</li>
<li>
  <a href="packages.html">Packages</a>
</li>
<li>
  <a href="https://goodekat.github.io/cv/goode_cv.pdf">CV</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="mailto:kgoode@iastate.edu">
    <span class="fa fa-envelope"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/goodekat">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/katherine-goode-363517a9/">
    <span class="fa fa-linkedin"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">




</div>


<p><br></p>
<p><img src="/images/rocks.jpg" width = 1000 /></p>
<p><br></p>
<div
id="tracing-trees-visualizing-random-forest-tree-variability-with-trace-plots"
class="section level4">
<h4><font color="#2B547E"> Tracing Trees: Visualizing Random Forest Tree
Variability with Trace Plots </font></h4>
<p><strong>July 11, 2022</strong> - Talk at Sandia National Labs</p>
<div id="slides" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2022-trace-plots/slides.html#1"><font color="#2B547E">Slides</font></a></h5>
</div>
<div id="code" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2022-trace-plots"><font color="#2B547E">
Code </font></a></h5>
<hr />
</div>
</div>
<div
id="whoseegg-a-shiny-app-for-identifying-invasive-carp-using-random-forests-and-fish-egg-characteristics"
class="section level4">
<h4><font color="#368BC1"> WhoseEgg: A Shiny App for Identifying
Invasive Carp Using Random Forests and Fish Egg Characteristics
</font></h4>
<p><strong>April 16, 2021</strong> - Talk given to the ISU <a
href="https://github.com/ISU-LunchinatoRs">LunchinatoRs</a> on the
WhoseEgg app</p>
<div id="slides-1" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2021-lunchinatoRs-shiny-fish/slides.html#1"><font color="#368BC1">Slides</font></a></h5>
</div>
<div id="code-1" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2021-lunchinatoRs-shiny-fish"><font color="#368BC1">Code</font></a></h5>
<hr />
</div>
</div>
<div
id="tracing-trees-visualizing-variability-in-the-architecture-of-random-forest-trees-using-extensions-of-trace-plots"
class="section level4">
<h4><font color="#342D7E"> Tracing Trees: Visualizing Variability in the
Architecture of Random Forest Trees Using Extensions of Trace Plots
</font></h4>
<p><strong>April 1, 2021</strong> - Talk for <a
href="https://isu-graphics.rbind.io/">ISU Graphics Group</a></p>
<p>Random forests are a popular method for statistical applications with
an objective of prediction. While an individual tree within a random
forest provides a clear decision path for how a prediction is made, the
ensemble of trees from the forest creates a complex decision process
that is difficult to interpret. One approach used to gain insight into
this decision process is visualization of the model. Various approaches
have been taken to visualize random forests including trace plots
developed by Simon Urbanek (<a
href="https://link.springer.com/chapter/10.1007/978-3-540-33037-0_11"
class="uri">https://link.springer.com/chapter/10.1007/978-3-540-33037-0_11</a>).
Trace plots depict the trees in a random forest using a structure
similar to parallel coordinate plots that allows for a direct comparison
of the trees. In this talk, I’ll describe trace plots and discuss my
recent work on implementing and extending trace plots in R. I’ll also
discuss my attempts to use trace plots to compare variability between
clusters of trees in a random forest and visualizing representative or
summary trees in the context of tree variability.</p>
<div id="slides-2" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2021-isugg-trace-plots/slides.html"><font color="#342D7E">Slides</font></a></h5>
</div>
<div id="code-2" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2021-isugg-trace-plots"><font color="#342D7E">Code</font></a></h5>
<hr />
</div>
</div>
<div
id="whoseegg-a-shiny-app-for-identifying-invasive-carp-using-random-forests-and-fish-egg-characteristics-1"
class="section level4">
<h4><font color="#2B547E"> WhoseEgg: A Shiny App for Identifying
Invasive Carp Using Random Forests and Fish Egg Characteristics
</font></h4>
<p><strong>February 25, 2021</strong> - Talk for <a
href="https://isu-graphics.rbind.io/">ISU Graphics Group</a></p>
<p>The fish species of Grass Carp (<em>Ctenopharyngodon idella</em>),
Silver Carp (<em>Hypophthalmichthys molitrix</em>), and Bighead Carp
(<em>H. nobilis</em>) are categorized as invasive carp in North America.
There is interest from a natural resource management perspective to
monitor the populations and spread of the fish species. A common
monitoring practice is to collect and genetically identify fish eggs,
but this process is both costly in money and time. <a
href="https://afspubs.onlinelibrary.wiley.com/doi/abs/10.1002/nafm.10380">Camacho
et al. (2019)</a> demonstrated the use of machine learning as a
possibility for a more efficient method of identifying invasive carp.
Camacho et al. (2019) trained random forests on easy to measure egg
characteristics such as water conductivity and average membrane
diameter, and the models returned high accuracy.</p>
<p>In this talk, I will present my recent work with Dr. Michael Weber
(NREM) and Dr. Philip Dixon on a Shiny app (WhoseEgg) for identifying
invasive carp using random forests based on those from Camacho et
al. (2019). The app is intended to be a tool for researchers to input
their own fish egg data and easily obtain random forest predictions via
a point-and-click user interface. We began work on the app in January,
so it is still in development. I will share the current state of the app
and our goals for enhancement. I will also ask the audience for
feedback. We would greatly appreciate suggestions for adjustments to
make the app more user friendly.</p>
<div id="slides-3" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2021-isugg-shiny-fish/slides.html#1"><font color="#2B547E">Slides</font></a></h5>
</div>
<div id="code-3" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2021-isugg-shiny-fish"><font color="#2B547E">
Code </font></a></h5>
<hr />
</div>
</div>
<div id="explaining-black-box-machine-learning-models"
class="section level4">
<h4><font color="#368BC1"> Explaining Black Box Machine Learning Models
</font></h4>
<p><strong>November 20, 2020</strong> - Talk given to the ACS Data
Analytics team at <a href="https://www.autodesk.com/">Autodesk</a> on an
overview of explainable machine learning with <a
href="https://annielyu.com/">Xiaodan (Annie) Lyu</a>.</p>
<div id="slides-4" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2020-autodesk-eml/slides.pdf"><font color="#368BC1">Slides</font></a></h5>
<hr />
</div>
</div>
<div id="the-delta-method-and-applications-to-mark-recapture-models"
class="section level4">
<h4><font color="#342D7E"> The Delta Method and Applications to Mark
Recapture Models</font></h4>
<p><strong>November 16, 2020</strong> - Talk for <a
href="https://www.nrem.iastate.edu/people/robert-klaver">Bob
Klaver’s</a> ISU Ecology 607 class</p>
<p>This talk discusses the delta method and ways to apply it in R</p>
<div id="slides-5" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2020-isu-delta-method/slides.html#1"><font color="#342D7E">Slides</font></a></h5>
</div>
<div id="code-4" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2020-isu-delta-method"><font color="#342D7E">Code</font></a></h5>
<hr />
</div>
</div>
<div
id="explaining-neural-networks-with-functional-data-using-pca-and-feature-importance"
class="section level4">
<h4><font color="#2B547E"> Explaining Neural Networks with Functional
Data Using PCA and Feature Importance </font></h4>
<p><strong>November 14, 2020</strong> - Talk for AAAI 2020 Fall
Symposium on AI in the Government and Public Sector</p>
<p>Optical spectral-temporal signatures extracted from videos of
explosions provide information for identifying characteristics of the
corresponding explosive devices. Currently, the identification is done
using heuristic algorithms and direct subject matter expert review. An
improvement in predictive performance may be obtained by using machine
learning, but this application lends itself to high consequence national
security decisions, so it is not only important to provide high accuracy
but clear explanations for the predictions to garner confidence in the
model. While much work has been done to develop explainability methods
for machine learning models, not much of the work focuses on situations
with input variables of the form of functional data such optical
spectral-temporal signatures. We propose a procedure for explaining
machine learning models fit using functional data that accounts for the
functional nature the data. Our approach makes use of functional
principal component analysis (fPCA) and permutation feature importance
(PFI). fPCA is used to transform the functions to create uncorrelated
functional principal components (fPCs). The model is trained using the
fPCs as inputs, and PFI is applied to identify the fPCs important to the
model for prediction. Visualizations are used to interpret the
variability explained by the fPCs that are found to be important by PFI
to determine the aspects of the functions that are important for
prediction. We demonstrate the technique by explaining neural networks
fit to explosion optical spectral-temporal signatures for predicting
characteristics of the explosive devices.</p>
<p>Sandia National Laboratories is a multimission laboratory managed and
operated by National Technology &amp; Engineering Solutions of Sandia,
LLC, a wholly owned subsidiary of Honeywell International Inc., for the
U.S. Department of Energy’s National Nuclear Security Administration
under contract DE-NA0003525. This paper describes objective technical
results and analysis. Any subjective views or opinions that might be
expressed in the paper do not necessarily represent the views of the
U.S. Department of Energy or the United States Government.
SAND2020-12004 C</p>
<div id="slides-6" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2020-aaai-fpca-pfi/slides.pdf"><font color="#2B547E">Slides</font></a></h5>
</div>
<div id="youtube-video" class="section level5">
<h5><a href="https://www.youtube.com/watch?v=8UxKbfUyc2M&t=273s"><font color="#2B547E">
YouTube Video </font></a></h5>
</div>
<div id="conference-paper" class="section level5">
<h5><a href="https://arxiv.org/abs/2010.12063"><font color="#2B547E">Conference
Paper</font></a></h5>
<hr />
</div>
</div>
<div id="a-statistical-consultants-perspective-on-getting-help-with-r"
class="section level4">
<h4><font color="#368BC1"> A Statistical Consultant’s Perspective on
Getting Help with R </font></h4>
<p><strong>October 2, 2020</strong> - Talk given with AES Statistical
Consultants (Haoyan Hu, Miranda Tilton, and Yudi Zhang) at ISU
LunchinatoRs</p>
<p>Everyone runs into problems when writing code in R (even
statisticians). Sometimes the problems are small picture such as bugs in
the code. Other times the problems are large picture such as how to
implement an analysis all together. In this talk, we will provide a
statistical consultant’s perspective on getting help with R. We’ll tell
about the resources our consulting group provides to ISU graduate
students who need help with R code and/or statistical analysis for a
research project. We’ll also cover resources for helping yourself,
internet resources for asking questions about R, and tips for practicing
a good work flow in R that will hopefully help to avoid problems.</p>
<div id="slides-7" class="section level5">
<h5><a href="https://goodekat.github.io/consulting-at-lunchinatoRs/slides.html"><font color="#368BC1">Slides</font></a></h5>
</div>
<div id="code-5" class="section level5">
<h5><a href="https://github.com/goodekat/consulting-at-lunchinatoRs"><font color="#368BC1">Code</font></a></h5>
<hr />
</div>
</div>
<div
id="explaining-neural-network-predictions-for-functional-data-using-principal-component-analysis-and-feature-importance"
class="section level4">
<h4><font color="#342D7E"> Explaining Neural Network Predictions for
Functional Data Using Principal Component Analysis and Feature
Importance </font></h4>
<p><strong>September 24, 2020</strong> - Talk for ISU graphics group</p>
<p>Explainable machine learning has become a quickly growing area of
research as the use of black-box models continues to increase. While
many methods have been proposed, little research has been done relating
to applications involving functional data. As an intern at Sandia
National Laboratories, I have been helping to develop methods to provide
explanations for an application focused on predicting explosive device
characteristics using optical spectral-temporal signatures from
explosions. In this talk, I’ll discuss our approach that involves
transforming the functions using functional principal component
analysis, training neural networks on the functional principal
components, and using permutation feature importance (PFI) to identify
the principal components that are important for prediction.
Visualization has played a key role in the interpretation of the
functional principal components identified as important by PFI to
understand the functional variability in the signatures that is driving
the predictions made by the neural networks.</p>
<p>Sandia National Laboratories is a multimission laboratory managed and
operated by National Technology &amp; Engineering Solutions of Sandia,
LLC, a wholly owned subsidiary of Honeywell International Inc., for the
U.S. Department of Energy’s National Nuclear Security Administration
under contract DE-NA0003525. SAND no: SAND2020-10057 A</p>
<div id="slides-8" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2020-isugg-fpca-pfi/slides_with_SAND.pdf"><font color="#342D7E">Slides</font></a></h5>
<hr />
</div>
</div>
<div
id="an-overview-of-visualization-techniques-for-explainable-machine-learning"
class="section level4">
<h4><font color="#2B547E"> An Overview of Visualization Techniques for
Explainable Machine Learning </font></h4>
<p><strong>April 10, 2020</strong> - Talk for ISU graphics group</p>
<p>Machine learning models are excellent predictors, but it is
impractical to interpret many of these models. Despite this
impracticality, it is important to be able to explain predictions to
assess and validate models. As a result, a field of research has
recently developed in the explainability of machine learning models. In
this talk, I will provide an overview of explainable machine learning
with a focus on visualization methods. I will discuss philosophies of
“explainability”, model agnostic and model specific visualization
methods, and code for creating some of the visualizations in R. I hope
that this talk will provide listeners with an introduction to
explainable machine learning and resources to learn more if desired.</p>
<div id="slides-9" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2020-isugg-iml/slides.html#1"><font color="#2B547E">Slides</font></a></h5>
</div>
<div id="code-6" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2020-isugg-iml"><font color="#2B547E">Code</font></a></h5>
<hr />
</div>
</div>
<div
id="visual-diagnostics-of-a-model-explainer-tools-for-the-assessment-of-lime-explanations"
class="section level4">
<h4><font color="#368BC1"> Visual Diagnostics of a Model Explainer:
Tools for the Assessment of LIME Explanations </font></h4>
<p><strong>December 3, 2019</strong> - Talk on my research at Sandia</p>
<p>A desire to be able to interpret machine learning models has led to
an area of research focused on providing explanations for predictions
made by black-box models. One method that has resulted from this area of
research is LIME (Ribeiro et. al. 2016). LIME stands for local
interpretable model-agnostic explanations. The method provides an
explanation for a black box prediction by using an interpretable model,
referred to as an explainer model, to approximate the complex black-box
model in a local region around a prediction of interest. The quality of
the explanation produced by LIME will depend on how good of an
approximation the interpretable model is to the complex model.
Currently, few tools have been provided to assess this approximation. We
are developing visualizations that diagnose the explanation produced by
LIME. In this talk, I will provide a brief overview of LIME, motivate
the importance of the assessing LIME explanations, and introduce our
diagnostic visualizations.</p>
<div id="slides-10" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2019-sandia-lime-diagnostics/slides.html"><font color="#368BC1">Slides</font></a></h5>
</div>
<div id="code-7" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2019-sandia-lime-diagnostics"><font color="#368BC1">Code</font></a></h5>
<hr />
</div>
</div>
<div id="gganimate-with-a-spooky-twist" class="section level4">
<h4><font color="#342D7E"> gganimate (with a spooky twist) </font></h4>
<p><strong>October 31, 2019</strong> - Talk for ISU graphics group</p>
<p>gganimate allows for the animation of ggplot2 graphics. The package
has been around for a while, but it has been updated to allow for easier
transitions from static ggplot2 graphic to animated versions. This talk
is meant to be an interactive tutorial on how to use the updated version
of gganimate. You are encouraged to bring a laptop to follow along.
Since the talk will be given on Halloween, spooky datasets will be used
to demonstrate the functionality of gganimate.</p>
<div id="slides-11" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2019-isugg-gganimate-spooky/slides.html"><font color="#342D7E">Slides</font></a></h5>
</div>
<div id="code-8" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2019-isugg-gganimate-spooky"><font color="#342D7E">Code</font></a></h5>
<hr />
</div>
</div>
<div id="ggresidpanel-easy-creation-of-panels-of-diagnostics-plots"
class="section level4">
<h4><font color="#2B547E"> ggResidpanel: Easy Creation of Panels of
Diagnostics Plots </font></h4>
<p><strong>October 4, 2019</strong> - Presentation for ISU
lunchinatoRs</p>
<p>Overview and tutorial on ggResidpanel.</p>
<div id="slides-12" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2019-lunchinatoRs-ggResidpanel/slides.html"><font color="#2B547E">Slides</font></a></h5>
</div>
<div id="code-9" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2019-lunchinatoRs-ggResidpanel"><font color="#2B547E">Code</font></a></h5>
<hr />
</div>
</div>
<div
id="visual-diagnostics-of-a-model-explainer-tools-for-the-assessment-of-lime-explanations-from-random-forests"
class="section level4">
<h4><font color="#368BC1"> Visual Diagnostics of a Model Explainer:
Tools for the Assessment of LIME Explanations from Random Forests
</font></h4>
<p><strong>July 29, 2019</strong> - Speed presentation and e-poster for
JSM 2019</p>
<p>Random forests are known for their accurate predictive abilities, but
they are a part of the family of machine learning models that lack
interpretability. A technique called LIME was developed to provide local
interpretations for predictive models. The technique fits a ridge
regression model to binary encoded perturbations created from the
observed data weighted by proximity to the prediction of interest. The
predicted values associated with the perturbations computed using the
complex model are used as the response variable in the regression. The
coefficients from the linear model are then used to determine the
influential variables. We have developed some visualizations and other
diagnostic tools to assess the explanations produced by LIME from a
random forest. In particular, we consider how well the simple model fit
by LIME captures the random forest model and how the results from LIME
vary based on different algorithm input options. To demonstrate these
tools, we apply LIME to a random forest fit to a forensics bullet
matching dataset using the lime R package and apply our methods to
diagnose the LIME explanations.</p>
<div id="slides-13" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2019-jsm-lime_diagnostics/slides.pdf"><font color="#368BC1">Slides</font></a></h5>
</div>
<div id="poster" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2019-jsm-lime_diagnostics/poster.pdf"><font color="#368BC1">Poster</font></a></h5>
</div>
<div id="code-10" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2019-jsm-lime_diagnostics"><font color="#368BC1">Code</font></a></h5>
<hr />
</div>
</div>
<div id="a-review-and-discussion-of-residuals-for-mixed-models"
class="section level4">
<h4><font color="#342D7E"> A Review and Discussion of Residuals for
Mixed Models </font></h4>
<p><strong>June 20, 2019</strong> - Talk for NCCC-170 meeting 2019</p>
<p>Residuals are a key tool used to diagnose models. As a statistical
consultant for researchers in many areas, I often find myself reminding
my clients to visualize residuals to assess model assumptions. Many of
my clients are working with mixed models, and I recently realized that I
often recommend the use of certain residual types without a full
understanding of the implications of selecting one type over another.
This led me to have an interest in better understanding the many
residuals types for mixed model. In this talk, I will provide a review
of the residual types available for linear mixed models (marginal,
conditional, studentized, etc.). I will explain how the residuals are
computed and how these computations differ between R and SAS. I will
also discuss what I have learned from the literature about how to select
a residual type when assessing a model. Lastly, I will briefly touch on
residual types for generalized linear mixed models and list some
unanswered questions. If time permits, I will pose these remaining
questions to the attendees to discuss as a group.</p>
<div id="slides-14" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2019-nccc-lmm_residuals/slides.html"><font color="#342D7E">Slides</font></a></h5>
</div>
<div id="code-11" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2019-nccc-lmm_residuals"><font color="#342D7E">Code</font></a></h5>
<hr />
</div>
</div>
<div
id="using-lime-to-interpret-a-random-forest-model-with-an-application-to-bullet-matching-data"
class="section level4">
<h4><font color="#2B547E"> Using LIME to Interpret a Random Forest Model
with an Application to Bullet Matching Data </font></h4>
<p><strong>May 13, 2019</strong> - Poster for Midwest Statistical
Machine Learning Colloquium</p>
<p><strong>April 10, 2019</strong> - Poster for Iowa State University
Graduate and Professional Student Research Conference</p>
<p>Random forests are known for their accurate predictive abilities, but
they are a part of the family of machine learning models that lack
interpretability. Recently, a technique called LIME was developed to
provide local interpretations for complex predictive models. LIME
determines which variables are important in a prediction of interest by
fitting a local linear regression to model predictions and perturbations
of the data. The coefficients from the linear model are used to
interpret the complex model. While applying LIME to random forests, I
encountered some unusual results. This led me to develop some diagnostic
tools to evaluate LIME. I will demonstrate these by assessing the
application of LIME to a random forest fit to a forensics bullet
matching dataset.</p>
<div id="poster-1" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2019-gpsrc-limetorf/poster.pdf"><font color="#2B547E">Poster</font></a></h5>
</div>
<div id="code-12" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2019-gpsrc-limetorf"><font color="#2B547E">Code</font></a></h5>
<hr />
</div>
</div>
<div id="an-application-of-lime-to-a-random-forest-model"
class="section level4">
<h4><font color="#368BC1"> An Application of LIME to a Random Forest
Model </font></h4>
<p><strong>March 1, 2019</strong> - Talk for ISU graphics group</p>
<p>Random forests are known for their accurate predictive abilities, but
they are a part of the family of machine learning models that lack
interpretability. A technique called LIME was developed to provide local
interpretations for black-box predictive models. In this talk, I will
explain the LIME procedure and show an application of LIME to
predictions from a random forest model fit to a bullet matching dataset.
I will present a Shiny app I created to view the LIME explanations.
Additionally, I will discuss the issues that I have encountered while
working with LIME, some of the attempts at a solution, and future
directions for my research.</p>
<div id="slides-15" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2019-isugg-limetorf/slides.html"><font color="#368BC1">Slides</font></a></h5>
</div>
<div id="code-13" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2019-isugg-limetorf"><font color="#368BC1">Code</font></a></h5>
<hr />
</div>
</div>
<div
id="introducing-ggresidpanel-an-r-package-for-easy-visualization-of-residuals"
class="section level4">
<h4><font color="#342D7E"> Introducing ggResidpanel: An R Package for
Easy Visualization of Residuals </font></h4>
<p><strong>October 12, 2018</strong> - Talk for ISU graphics group with
Dr. Katie Rey</p>
<p><strong>May 8, 2018</strong> - Poster for Kansas State University
Conference on Applied Statistics in Agriculture</p>
<p>As consultants on a wide variety of projects across many majors, a
common oversight we encounter is a failure to examine the residuals.
This is particularly true when the client is performing the analysis in
R. We were inspired by the residual panel in SAS to create an R package
that easily provides users with a similar panel of plots. The
ggResidpanel package in R is intended to give a single view of
diagnostic plots for checking the key underlying assumptions of linear
models. A variety of options gives the user the ability to choose from a
selection of plots to display in a window. This includes SAS’s default
residual panel as well as R’s default plots for linear models. Other
options have been included to ensure that this package can also be
applied to deviance or Pearson residuals if the user inputs a
generalized linear model. Cook’s D plots and interactive plots using
Plotly are included to provide a straightforward process to identify
outliers and influential points while connecting findings back to the
data.</p>
<div id="talk" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2018-isugg-ggResidpanel/talk.html"><font color="#342D7E">Talk</font></a></h5>
</div>
<div id="poster-2" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2018-kstate-ggresidpanel/poster.pdf"><font color="#342D7E">Poster</font></a></h5>
</div>
<div id="code-14" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2018-isugg-ggResidpanel"><font color="#342D7E">Code</font></a></h5>
<hr />
</div>
</div>
<div id="interpreting-predictions-from-black-box-models-with-lime"
class="section level4">
<h4><font color="#2B547E"> Interpreting Predictions from Black Box
Models with LIME </font></h4>
<p><strong>November 9, 2017</strong> - Talk for ISU graphics group</p>
<p>LIME (Local Interpretable Model-agnostic Explanations) is a method
that explains how black box models determine individual predictions. It
was developed by computer scientists at the University of Washington and
implemented in Python, and recently, Thomas Pedersen developed the R
package lime that allows R users to implement the procedure. In this
talk, I will explain the motivation for LIME, discuss how it works, and
show examples using LIME in R. Additionally, I will encourage
participation as we work through an example the creators of LIME used to
test the usefulness of LIME, so please bring your laptop if
possible.</p>
<div id="slides-16" class="section level5">
<h5><a href="https://goodekat.github.io/presentations/2017-isugg-lime/slides.html"><font color="#2B547E">Slides</font></a></h5>
</div>
<div id="code-15" class="section level5">
<h5><a href="https://github.com/goodekat/presentations/tree/master/2017-isugg-lime"><font color="#2B547E">Code</font></a></h5>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
